{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model using hyperopt library to tune hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrangling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "import xgboost as xgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin,tpe,hp,STATUS_OK,Trials\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "\n",
    "from typing import Any, Dict, Union\n",
    "\n",
    "def hyperparameter_tuning(hyperparams: Dict[str,Union[float,int]],\n",
    "                          kag_X_train:pd.DataFrame,\n",
    "                          kag_y_train:pd.Series,\n",
    "                          kag_X_test:pd.DataFrame,\n",
    "                          kag_y_test:pd.Series,\n",
    "                          early_stopping_rounds:int=50,\n",
    "                          metric:callable=accuracy_score)->Dict[str, Any]:\n",
    "    int_vals=['max_depth','reg_alpha']\n",
    "    hyperparams={k:(int(val) if k in int_vals else val)\n",
    "           for k,val in hyperparams.items()}\n",
    "    hyperparams['early_stopping_rounds']= early_stopping_rounds\n",
    "    model = xgb.XGBClassifier(**hyperparams)\n",
    "    evaluation=[(kag_X_train,kag_y_train),(kag_X_test,kag_y_test)]\n",
    "\n",
    "    model.fit(kag_X_train,kag_y_train,\n",
    "              eval_set=evaluation,\n",
    "              verbose=False)\n",
    "    pred=model.predict(kag_X_test)\n",
    "    score=metric(kag_y_test,pred)\n",
    "    return{'loss':-score,'status':STATUS_OK,'model':model}\n",
    "\n",
    "hyperparams={'max_depth':hp.quniform('max_depth',1,8,1),\n",
    "         'min_child_weight':hp.loguniform('min_child_weight',-2,3),\n",
    "         'subsample':hp.uniform('subsample',0.5,1),\n",
    "         'colsample_bytree':hp.uniform('colsample_bytree',0.5,1),\n",
    "         'reg_alpha':hp.uniform('reg_alpha',0,10),\n",
    "         'reg_lambda':hp.uniform('reg_lambda',1,10),\n",
    "         'gamma':hp.loguniform('gamma',-10,10),\n",
    "         'learning_rate':hp.loguniform('learning_rate',-7,0),\n",
    "       #   'random_state':42\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to run hyperopt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [13:07<00:00,  2.54trial/s, best loss: -0.8109062377402904]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8037808098513046,\n",
       " 'gamma': 8.519420372081054,\n",
       " 'learning_rate': 0.2047887166422218,\n",
       " 'max_depth': 4.0,\n",
       " 'min_child_weight': 11.28319186084241,\n",
       " 'reg_alpha': 1.2941127471018976,\n",
       " 'reg_lambda': 1.976995326435837,\n",
       " 'subsample': 0.6797060965412611}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trials=Trials()\n",
    "# best=fmin(fn=lambda hyperparams: hyperparameter_tuning(hyperparams,kag_X_train,kag_y_train,kag_X_test,kag_y_test),\n",
    "#           space=hyperparams,\n",
    "#           algo=tpe.suggest,\n",
    "#           max_evals=2_000,\n",
    "#           trials=trials)\n",
    "\n",
    "# best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with noisy data\n",
    "# best={'colsample_bytree': 0.8037808098513046,\n",
    "#  'gamma': 8.519420372081054,\n",
    "#  'learning_rate': 0.2047887166422218,\n",
    "#  'max_depth': 4.0,\n",
    "#  'min_child_weight': 11.28319186084241,\n",
    "#  'reg_alpha': 1.2941127471018976,\n",
    "#  'reg_lambda': 1.976995326435837,\n",
    "#  'subsample': 0.6797060965412611}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best={'colsample_bytree': 0.7548336147601576,\n",
    " 'gamma': 0.07384394880603823,\n",
    " 'learning_rate': 0.04687842221296814,\n",
    " 'max_depth': 4.0,\n",
    " 'min_child_weight': 0.32575523925747074,\n",
    " 'reg_alpha': 0.45553764910317607,\n",
    " 'reg_lambda': 6.713863245468691,\n",
    " 'subsample': 0.8380129565326875}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperopt score\n",
    "best['max_depth']=4\n",
    "xghpt=xgb.XGBClassifier(**best,n_estimators=500)\n",
    "xghpt.fit(Xtrain,ytrain)\n",
    "res=xghpt.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "result=pd.DataFrame({'PassengerId':raw_test.PassengerId,'Transported':res_encoder.inverse_transform(res)})\n",
    "result.to_csv('model1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
